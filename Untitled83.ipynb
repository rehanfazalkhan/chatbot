{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHATBOT  WITH DEEP NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing The Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations=open(r'C:\\Users\\SRKT\\Desktop\\dnlp\\movie_conversations.txt',encoding='utf-8',errors='ignore').read().split('\\n')\n",
    "lines=open(r'C:\\Users\\SRKT\\Desktop\\dnlp\\movie_lines.txt',encoding='utf-8',errors='ignore').read().split('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dictionary thats maps each line and each id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2line={}\n",
    "for line in lines:\n",
    "    _line=line.split(' +++$+++ ')\n",
    "    if len(_line)==5:\n",
    "        id2line[_line[0]]=_line[4]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating List of all the Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_ids=[]\n",
    "for conversation in conversations[:-1]:\n",
    "    _conversation=conversation.split(' +++$+++ ')[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n",
    "    conversations_ids.append(_conversation.split(','))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting separately ques & ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "questions=[]\n",
    "answers=[]\n",
    "for conversation in conversations_ids:\n",
    "    for i in  range(len(conversation )-1):\n",
    "        questions.append(id2line[conversation[i]])\n",
    "        answers.append(id2line[conversation[i+1]])\n",
    "        \n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing a first cleaning of the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub(r\"i'm\",\"i am\",text)\n",
    "    text=re.sub(r\"he's\",\"he is\",text)\n",
    "    text=re.sub(r\"she's\",\"she is\",text)\n",
    "    text=re.sub(r\"that's\",\"that is\",text)\n",
    "    text=re.sub(r\"what's\",\"what is\",text)\n",
    "    text=re.sub(r\"where's\",\"where is\",text)\n",
    "    text=re.sub(r\"he's\",\"he is\",text) \n",
    "    text=re.sub(r\"\\'ll'\",\"will \",text)\n",
    "    text=re.sub(r\"\\'ve'\",\"have\",text)\n",
    "    text=re.sub(r\"\\'re'\",\"are \",text)\n",
    "    text=re.sub(r\"\\d\",\"would \",text)\n",
    "    text=re.sub(r\"won't\",\"will not \",text)\n",
    "    text=re.sub(r\"can't\",\"cannot \",text)\n",
    "    text=re.sub(r\"\\'ll'\",\"will \",text)\n",
    "    text=re.sub(r\"[-()\\#*;<>{}+=.?!]\",\" \",text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_questions=[]\n",
    "for question in questions:\n",
    "    clean_questions.append(clean_text(question))\n",
    "clean_answers=[]\n",
    "for answer in answers:\n",
    "    clean_answers.append(clean_text(answer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dictionary that maps each word to its number of occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2count={}\n",
    "for question in clean_questions:\n",
    "    for word in question.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word]=1\n",
    "        else:\n",
    "            word2count[word]+=1\n",
    "            \n",
    "    \n",
    "for answer in clean_answers:\n",
    "    for word in answer.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word]=1\n",
    "        else:\n",
    "            word2count[word]+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating two dictionaries that map the questions words and the answers words to a unique integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=20\n",
    "questionsword2int={}\n",
    "word_number=0\n",
    "for word,count in word2count.items():\n",
    "    if count >=threshold:\n",
    "        questionsword2int[word]=word_number\n",
    "        word_number+=1\n",
    "answersword2int={}\n",
    "word_number=0\n",
    "for word,count in word2count.items():\n",
    "    if count >=threshold:\n",
    "        answersword2int[word]=word_number\n",
    "        word_number+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the last tokens to these two dictonaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=['<PAD>', '<EOS>','<OUT>', '<SOS>']\n",
    "for token in tokens:\n",
    "    questionsword2int[token]=len(questionsword2int)+1\n",
    "for token in tokens:\n",
    "    answersword2int[token]=len(answersword2int)+1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the inverse dictionary of the answerswords2int dictonary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "answersword2int={w_i:w for w,w_i in answersword2int.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the End of string token to the end of every answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(clean_answers)):\n",
    "    clean_answers[i] += '<EOS>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translating all the questions and the answers into integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_to_int=[]\n",
    "for question in clean_questions:\n",
    "    ints=[]\n",
    "    for word in question.split():\n",
    "        if word not in questionsword2int:\n",
    "            ints.append(questionsword2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(questionsword2int[word])\n",
    "    questions_to_int.append(ints)\n",
    "answers_to_int=[]\n",
    "for answer in clean_answers:\n",
    "    ints=[]\n",
    "    for word in answer.split():\n",
    "        if word not in answersword2int:\n",
    "            ints.append(answersword2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(answersword2int[word])\n",
    "    answers_to_int.append(ints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting questions and answers by length of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_clean_questions=[]\n",
    "sorted_clean_answers=[]\n",
    "for length in range(1,25 + 1):\n",
    "    for i in enumerate(questions_to_int):\n",
    "        if len(i[1])==length:\n",
    "            sorted_clean_questions.append(questions_to_int[i[0]])\n",
    "            sorted_clean_answers.append(answers_to_int[i[0]])\n",
    "            \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating placeholders for the inputs and the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input():\n",
    "    inputs=tf.placeholder(tf.int32,[None,None],name='input')\n",
    "    targets=tf.placeholder(tf.int32,[None,None],name='target')\n",
    "    lr=tf.placeholder(tf.float32,name='learning_rate')\n",
    "    keep_prob=tf.placeholder(tf.float,name='keep_prob')\n",
    "    return inputs,targets,lr,keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_targets(targets,word2int,batch_size):\n",
    "    left_side=tf.fill([batch_size,1],word2int['<SOS>'])\n",
    "    Right_side=tf.strided_slice(targets,[0,0],[batch_size-1],[1,1])\n",
    "    preprocess_targets=tf.concat([left_side,right_side],1)\n",
    "    return preprocess_targets\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Encoder RNN Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_rnn_layer(rnn_inputs,rnn_size,num_layers,keep_prob,sequence_length):\n",
    "    lstm=tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "    lstm_dropout=tf.contrib.rnn.DropoutWrapper(lstm,input_keep_prob=keep_prob)\n",
    "    encoder_cell=tf.contrib.rnn.MultiRNNCell([lstm_dropout]*num_layers)\n",
    "    encoder_output,encoder_state=tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,cell_bw=encoder_cell,sequence_length=sequence_lenght,inputs=rnn_inputs,dtype=tf.float32)\n",
    "    return encoder_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_training_set(encoder_state,decoder_cell,decoder_embedded_inputs,sequence_length,decoding_scope,output_function,keep_prob,batch_size ):\n",
    "    attention_states=tf.zeros([batch_size,1,decoder_cell.output_size])\n",
    "    attention_keys,attention_values,attention_score_function,attenstion_construct_fuction=tf.contrib.seq2seq.prepare_attention(attention_states,attention_option='bahdanau',num_units=decoder_cell.output.size)\n",
    "    training_decoder_function=tf.contrib.seq2seq.attention_decoder_fn_train(encoder_state[0],antention_keys,attention_values,attenstion_score_function,attention_construct_function,name='attn_dec_train')\n",
    "    decoder_output,decoder_final_state,decoder_final_context_state=tf.contrib.seq2seq.dynamic_rnn_decoder(decoder_cell,traning_decoder_function,decoder_embedded_input,sequence_length,scope=decoding_scope)\n",
    "    \n",
    "    decoder_output_dropout=tf.nn.dropout(decoder_output,keep_prob)\n",
    "    return output_function(decoder_output_dropout)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding  test/validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_test_set(encoder_state,decoder_cell,decoder_embedded_matrix,sos_id,eos_id,maximum_length,num_words,sequence_length,decoding_scope,output_function,keep_prob,batch_size ):\n",
    "    attention_states=tf.zeros([batch_size,1,decoder_cell.output_size])\n",
    "    attention_keys,attention_values,attention_score_function,attenstion_construct_fuction=tf.contrib.seq2seq.prepare_attention(attention_states,attention_option='bahdanau',num_units=decoder_cell.output.size)\n",
    "    test_decoder_function=tf.contrib.seq2seq.attention_decoder_fn_inference(output_function,encoder_state[0],antention_keys,attention_values,attenstion_score_function,attention_construct_function,decoder_embedded_matrix,sos_id,eos_id,maximum_length,num_words,name='attn_dec_inf')\n",
    "    test_predictions,decoder_final_state.decoder_final_context_state=tf.contrib.seq2seq.dynamic_rnn_decoder(decoder_cell,test_decoder_function,scope=decoding_scope)\n",
    "    \n",
    "    \n",
    "    return test_predictions\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Decoder RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_rnn(decoder_embedded_input,decoder_embedded_matrix,encoder_state,num_words,sequence_length,rnn_size,num_layers,word2int,keep_prob,batch_size):\n",
    "    with tf.variable_scope(\"decoding\") as decoding_scope:\n",
    "        lstm=tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "        lstm_dropout=tf.contrib.rnn.DropoutWrapper(lstm,input_keep_prob=keep_prob)\n",
    "        decoder_cell=tf.contrib.rnn.MultiRNNCell([lstm_dropout]*num_layers)\n",
    "        weights=tf.trucated_normal_intializer(stddev=0.1)\n",
    "        biases=tf.zeros_intializer()\n",
    "        output_function=lambda x:tf.contrib.fully_connected(x,num_words,scope=decoding_scope,weights_intializers=weights,biases_initializer=biases)\n",
    "        training_prediction=decode_training_set(encoder_state,decoder_cell,decoder_embedded_input,sequence_length,decoding_scope,output_function,keep_prob,batch_size)\n",
    "        decoding_scope.reuse_variables()\n",
    "        test_prediction=decode_test_set(encoder_state,decoder_cell,decoder_embedded_matrix,wordint['<SOS>'],wordint['<EOS>'],sequence_length-1,num_words,decoding_scope,output_function,keep_prob,batch_size)\n",
    "        \n",
    "    return training_predictions,test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bulding seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_model(inputs,targets,keep_prob,batch_size,sequence_length,answers_num_words,questions_num_words,encoder_embedding_size,decoder_embedding_size,rnn_size,num_layers,questionswords2int):\n",
    "    encoder_embedded_input=tf.contrib.layers.embed_sequence(inputs,answers_num_words+1,encoder_embedding_size,intializer=tf.random_uniform_initializer(0,1))\n",
    "    encoder_state=encoder_rnn(encoder_embedded_input,rnn_size,num_layers,keep_prob,sequence_lengths)\n",
    "    preprocessed_targets=preprocess_targets(targets,questionswords2int,batch_size)\n",
    "    decoder_embedded_matrix=tf.variable(tf.random_uniform([questions_num_words+1,decoder_embedding_size],0,1))\n",
    "    decoder_embedded_input=tf.nn.embedding_lookup(decoder_embedded_matrix,preprocessed_targets)\n",
    "    training_predictions,test_predictions=decoder_rnn(decoder_embedded_inputs,decoder_embedded_matrix,encoder_state,questions_num_words,sequence_length,rnn_size,num_layers,questionswords2int,keep_prob,batch_size)\n",
    "    return training_predictions,test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting the Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "batch_size=64\n",
    "rnn_size=512\n",
    "num_layers=3\n",
    "encoding_embedding_size=512\n",
    "decoding_embedding_size=512\n",
    "learning_rate=0.01\n",
    "learning_rate_decay=0.9\n",
    "min_learning_rate=0.0001\n",
    "keep_probability=0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "session=tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-5d85b566fa30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-18832f3e9f7e>\u001b[0m in \u001b[0;36mmodel_input\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtargets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mkeep_prob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'keep_prob'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'float'"
     ]
    }
   ],
   "source": [
    "inputs,targets,lr,keep_prob=model_input()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length=tf.placeholder_with_default(25,None,name='sequence_length')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shape of inputs tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=tf.shape(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
